Ideas.md

There needs to be a new JSON-based "feed" of the new data.  This needs to be generated by something like cron, because doing it after each post kills
responsiveness.  The real fix should be a scoreboard table that has a list of categories that need to be regenerated, and specific files to regenerate.

Upon posting, you issue some UPDATE queries to toggle regeneration.

A cron job sweeps the list and generates new feed files.

There should be feeds for: breaking, local, comments, features.  There should also be a composite feed that looks like this:

{ "_created" : epoch-int,
  "category": category-int,
  "breaking": [ .... ],
  "local": [ .... ],
  "comments": [ .... ],
  "features": [ .... ] }

 
The format for each feed is:
[
  { "title":"the title", "author":"the author", "date":"date", "uurl":"2013/01/02/352534", "thumb":1 },
  { "title":"the title", "author":"the author", "date":"date", "uurl":"2013/01/02/352534" },
  ...
]

uurl is micro-url, a fragment that is enough to construct the relevant URLs to get the story.

The pathname of each feed is: /cache/feeds/cat-id/.  
The filenames are all.json, breaking.json, local.json, comments.json, features.json.

There might also be another format, a binary format that's more like this:
TITLE__________________________________________________________________________\0DATEURL-----++++++++0\0




The entire feed can be extremely small.  The present RSS feed is over 100k.  
A fixed format can reduce that to 2k, and the indexes for the whole site can be 10k or so.

Articles are presently around 4k to 8k, but if we can remove some extraneous data we can get smaller. Compression also works well.

With an "i have" list of stories (see rn newsreader), the second request can include a list of the last articles read.
The server than then sweep up the new articles, and send them back as part of the second request.

